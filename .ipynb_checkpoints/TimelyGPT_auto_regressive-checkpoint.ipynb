{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad2e8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Including Uitilities and TimelyGPT Libraries\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import geomloss\n",
    "import itertools\n",
    "\n",
    "# --- Importing TimelyGPT module and configs ---\n",
    "# 将项目根目录添加到 Python 路径中\n",
    "project_root = str(pathlib.Path.cwd().resolve().parent)\n",
    "sys.path.insert(0, project_root)\n",
    "os.chdir(project_root)  # Change the current working directory to the project root\n",
    "\n",
    "from model.TimelyGPT_CTS.layers.configs import RetNetConfig\n",
    "from model.TimelyGPT_CTS.layers.Retention_layers import RetNetBlock\n",
    "\n",
    "# --- Importing utils ---\n",
    "from notebooks.BenchmarkUtils import loadSCData, tpSplitInd, splitBySpec\n",
    "from optim.evaluation import globalEvaluation\n",
    "from plotting.PlottingUtils import umapWithPCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddec770e-1c68-4985-b348-20e62292c3cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall torch numpy matplotlib time copy tqdm pathlib geomloss itertools\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2309\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2307\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2309\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.9/site-packages/IPython/core/magics/packaging.py:87\u001b[0m, in \u001b[0;36mPackagingMagics.conda\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"Run the conda package manager within the current kernel.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m  %conda install [pkgs]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_conda_environment():\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m conda \u001b[38;5;241m=\u001b[39m _get_conda_executable()\n\u001b[1;32m     91\u001b[0m args \u001b[38;5;241m=\u001b[39m shlex\u001b[38;5;241m.\u001b[39msplit(line)\n",
      "\u001b[0;31mValueError\u001b[0m: The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead."
     ]
    }
   ],
   "source": [
    "pip install torch numpy matplotlib time copy tqdm pathlib geomloss itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83891efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE and TimelyGPT Model Definitions\n",
    "class TimelyGPT_CellLevel(nn.Module):\n",
    "    \"\"\"\n",
    "    TimelyGPT for cell-level trajectory prediction.\n",
    "    Input: multiple cells at initial timepoint\n",
    "    Output: predicted states of these cells at future timepoints\n",
    "    \n",
    "    [MODIFIED] This version uses auto-regressive \"GPT-style\" generation\n",
    "    instead of broadcasting z0.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, latent_dim):\n",
    "        super(TimelyGPT_CellLevel, self).__init__()\n",
    "\n",
    "        self.num_layers = config.num_layers\n",
    "        self.d_model = config.d_model\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Input projection to model dimension\n",
    "        self.input_projection = nn.Linear(latent_dim, config.d_model)\n",
    "\n",
    "        # Time embedding, which is learnable\n",
    "        # self.time_embedding = nn.Embedding(20, config.d_model) # <-- REMOVED as requested\n",
    "\n",
    "        # RetNet blocks\n",
    "        self.blocks = nn.ModuleList([RetNetBlock(config) for _ in range(self.num_layers)])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        self.output_projection = nn.Linear(config.d_model, latent_dim)\n",
    "        \n",
    "        self.gradient_checkpointing = config.use_grad_ckp if hasattr(config, 'use_grad_ckp') else False\n",
    "    \n",
    "    # [MODIFIED] This entire 'forward' method is replaced\n",
    "    def forward(self, cells_latent, time_indices, forward_impl='parallel'): # Signature kept for compatibility\n",
    "        \"\"\"\n",
    "        Predict future states for a batch of cells using auto-regressive \"GPT-style\" generation.\n",
    "        \n",
    "        Args:\n",
    "            cells_latent: [n_cells, latent_dim] - initial cell states (z0) in latent space\n",
    "            time_indices: [n_timepoints] - indices of timepoints to predict (e.g., [0, 1, ..., 11])\n",
    "            forward_impl: (Ignored) Kept for compatibility. Logic is now always recurrent.\n",
    "        Returns:\n",
    "            predictions: [n_cells, n_timepoints, latent_dim] - predicted cell states [z0_pred, z1_pred, ...]\n",
    "        \"\"\"\n",
    "        n_cells = cells_latent.shape[0]\n",
    "        n_timepoints = len(time_indices)\n",
    "        \n",
    "        predictions_list = []\n",
    "        \n",
    "        # Initialize past_key_values for each layer's recurrent state\n",
    "        past_key_values = [None] * self.num_layers\n",
    "        \n",
    "        # The first input (for t=0) is the encoded z0 from the VAE\n",
    "        current_latent_input = cells_latent  # [n_cells, latent_dim]\n",
    "        \n",
    "        # Loop for each timepoint to generate auto-regressively\n",
    "        for t in range(n_timepoints):\n",
    "            # 1. Project current latent input (z_t) to hidden state (h_t)\n",
    "            # Input to blocks needs shape: [n_cells, 1, d_model]\n",
    "            h_current_step_input = self.input_projection(current_latent_input).unsqueeze(1)\n",
    "            \n",
    "            new_past_key_values = []\n",
    "            \n",
    "            # 2. Pass through RetNet blocks (must use recurrent mode)\n",
    "            for i, block in enumerate(self.blocks):\n",
    "                block_outputs = block(\n",
    "                    h_current_step_input,\n",
    "                    retention_mask=None,\n",
    "                    forward_impl='recurrent',  # This logic requires the recurrent implementation\n",
    "                    past_key_value=past_key_values[i],\n",
    "                    sequence_offset=t,  # Pass current time 't' for RoPE/xPos\n",
    "                    chunk_size=None,\n",
    "                    output_retentions=False\n",
    "                )\n",
    "                h_current_step_input = block_outputs[0]  # Output hidden state [n_cells, 1, d_model]\n",
    "                new_past_key_values.append(block_outputs[1]) # Save new recurrent state\n",
    "            \n",
    "            # Update the past_key_values for the next iteration\n",
    "            past_key_values = new_past_key_values\n",
    "            \n",
    "            # 3. Get output hidden state from the last block\n",
    "            # h_current_output: [n_cells, d_model]\n",
    "            h_current_output = h_current_step_input.squeeze(1)\n",
    "            \n",
    "            # 4. Project back to latent space to get prediction for this step (z_t_pred)\n",
    "            # z_pred_current_step: [n_cells, latent_dim]\n",
    "            z_pred_current_step = self.output_projection(self.ln_f(h_current_output))\n",
    "            \n",
    "            # 5. Store prediction\n",
    "            predictions_list.append(z_pred_current_step)\n",
    "            \n",
    "            # 6. Set the output prediction as the input for the *next* time step\n",
    "            current_latent_input = z_pred_current_step\n",
    "        \n",
    "        # Stack all predictions along the time dimension\n",
    "        # predictions: [n_cells, n_timepoints, latent_dim]\n",
    "        predictions = torch.stack(predictions_list, dim=1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# --- VAE Model Definition ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_genes, latent_dim, hidden_dims=[128, 128]):\n",
    "        super(Encoder, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = n_genes\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = h_dim\n",
    "        self.encoder_net = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_log_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder_net(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_log_var(h)\n",
    "        return mu, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, n_genes, hidden_dims=[128, 128]):\n",
    "        super(Decoder, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = latent_dim\n",
    "        # Use a reversed architecture for the decoder\n",
    "        reversed_hidden_dims = list(reversed(hidden_dims))\n",
    "        for h_dim in reversed_hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = h_dim\n",
    "        layers.append(nn.Linear(reversed_hidden_dims[-1], n_genes))\n",
    "        self.decoder_net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Handle 3D input for trajectory decoding\n",
    "        if z.dim() == 3:\n",
    "            n_cells, n_timepoints, latent_dim = z.shape\n",
    "            z_flat = z.reshape(-1, latent_dim)\n",
    "            recon_flat = self.decoder_net(z_flat)\n",
    "            return recon_flat.reshape(n_cells, n_timepoints, -1)\n",
    "        else:\n",
    "            return self.decoder_net(z)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, n_genes, latent_dim, enc_hidden_dims=[128, 128], dec_hidden_dims=[128, 128]):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(n_genes, latent_dim, enc_hidden_dims)\n",
    "        self.decoder = Decoder(latent_dim, n_genes, dec_hidden_dims)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, z, mu, log_var\n",
    "\n",
    "# --- Combined VAE-TimelyGPT Model ---\n",
    "class VAETimelyGPT(nn.Module):\n",
    "    def __init__(self, vae, timely_gpt):\n",
    "        super(VAETimelyGPT, self).__init__()\n",
    "        self.vae = vae\n",
    "        self.timely_gpt = timely_gpt\n",
    "\n",
    "    def forward(self, initial_cells_obs, time_indices, forward_impl='parallel'):\n",
    "        \"\"\"\n",
    "        Forward pass matching scNODE style:\n",
    "        1. Encode initial cells to latent space\n",
    "        2. Predict future latent states with TimelyGPT (replacing ODE)\n",
    "        3. Decode predicted latent states back to gene space\n",
    "        Returns: recon_obs, first_latent_dist (mu, log_var), first_tp_data, latent_seq\n",
    "        \"\"\"\n",
    "        # 1. Encode initial cells to latent space\n",
    "        mu, log_var = self.vae.encoder(initial_cells_obs)\n",
    "        z_initial = self.vae.reparameterize(mu, log_var)\n",
    "\n",
    "        # 2. Predict future latent states with TimelyGPT\n",
    "        # z_predictions (latent_seq): [n_cells, n_timepoints, latent_dim]\n",
    "        latent_seq = self.timely_gpt(z_initial, time_indices, forward_impl)\n",
    "\n",
    "        # 3. Decode predicted latent states back to gene space\n",
    "        recon_obs = self.vae.decoder(latent_seq)\n",
    "\n",
    "        # Return format matching scNODE: (recon_obs, first_latent_dist, first_tp_data, latent_seq)\n",
    "        first_latent_dist = (mu, log_var)\n",
    "        first_tp_data = initial_cells_obs\n",
    "        \n",
    "        return recon_obs, first_latent_dist, first_tp_data, latent_seq\n",
    "\n",
    "\n",
    "def plotPredTestTime(true_umap, pred_umap, true_tps, pred_tps, test_tps_list, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot UMAP visualization comparing true and predicted data at test timepoints.\n",
    "    Left: True data (all timepoints in gray, test timepoints highlighted)\n",
    "    Right: Predicted data (all timepoints in gray, test timepoints highlighted)\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mcolors\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    gray_color = \"#D3D3D3\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Left plot: True data\n",
    "    ax1.set_title(\"True Data\", fontsize=15)\n",
    "    ax1.scatter(true_umap[:, 0], true_umap[:, 1], c=gray_color, s=20, alpha=0.5, label=\"other\")\n",
    "    for i, t in enumerate(test_tps_list):\n",
    "        mask = true_tps == t\n",
    "        if np.any(mask):\n",
    "            ax1.scatter(true_umap[mask, 0], true_umap[mask, 1], \n",
    "                       c=colors[i % len(colors)], s=30, alpha=1.0, label=f\"t={int(t)}\")\n",
    "    ax1.set_xlabel(\"UMAP 1\"), ax1.set_ylabel(\"UMAP 2\")\n",
    "    ax1.legend(loc=\"best\")\n",
    "    \n",
    "    # Right plot: Predicted data\n",
    "    ax2.set_title(\"Predictions (VAE + TimelyGPT)\", fontsize=15)\n",
    "    ax2.scatter(true_umap[:, 0], true_umap[:, 1], c=gray_color, s=20, alpha=0.5, label=\"other\")\n",
    "    for i, t in enumerate(test_tps_list):\n",
    "        mask = pred_tps == t\n",
    "        if np.any(mask):\n",
    "            ax2.scatter(pred_umap[mask, 0], pred_umap[mask, 1],\n",
    "                       c=colors[i % len(colors)], s=30, alpha=1.0, label=f\"t={int(t)}\")\n",
    "    ax2.set_xlabel(\"UMAP 1\"), ax2.set_ylabel(\"UMAP 2\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Configs ---\n",
    "DATA_NAME, SPLIT_TYPE = \"zebrafish\", \"three_interpolation\"\n",
    "LATENT_DIM = 64\n",
    "NUM_HEADS = 8 # should be divisor of d_model\n",
    "LATENT_COEFF = 1.0  # Regularization coefficient for latent trajectory smoothing (beta)\n",
    "N_PRED_CELLS = 5000  # Number of cells to predict\n",
    "EPOCHS = 10  # Maximum number of main training epochs\n",
    "ITERS_PER_EPOCH = 100  # Number of iterations per epoch\n",
    "BATCH_SIZE = 32\n",
    "PRETRAIN_LR = 3e-4\n",
    "PRETRAIN_ITERS = 500  # Number of pre-training iterations\n",
    "LR = 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LR} with exponential decay (gamma=0.99)\")\n",
    "print(f\"Pre-training iterations: {PRETRAIN_ITERS}\")\n",
    "print(f\"Latent smoothing coefficient: {LATENT_COEFF}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data loading and preprocessing ---\n",
    "ann_data, cell_tps, cell_types, n_genes, n_tps, all_tps = loadSCData(DATA_NAME, SPLIT_TYPE)\n",
    "train_tps_idx, test_tps_idx = tpSplitInd(DATA_NAME, SPLIT_TYPE)\n",
    "data = ann_data.X\n",
    "\n",
    "# Convert to torch tensors (cell_tps ranges from 1 to n_tps)\n",
    "traj_data = [torch.FloatTensor(data[np.where(cell_tps == t)[0], :]) for t in range(1, n_tps + 1)]\n",
    "all_tps = list(all_tps)  # Convert to list\n",
    "train_data, test_data = splitBySpec(traj_data, train_tps_idx, test_tps_idx)\n",
    "n_cells = [each.shape[0] for each in traj_data]\n",
    "\n",
    "print(f\"# timepoints={n_tps}, # genes={n_genes}\")\n",
    "print(f\"# cells per timepoint: {n_cells}\")\n",
    "print(f\"Train timepoints: {train_tps_idx}\")\n",
    "print(f\"Test timepoints: {test_tps_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeefa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model  ---\n",
    "# 1. VAE model\n",
    "vae = VAE(n_genes, LATENT_DIM).to(DEVICE)\n",
    "\n",
    "# 2. TimelyGPT model\n",
    "timely_gpt_config = RetNetConfig(\n",
    "    num_layers=3,\n",
    "    num_heads=NUM_HEADS,\n",
    "    d_model=LATENT_DIM,\n",
    "    qk_dim=LATENT_DIM,\n",
    "    v_dim=LATENT_DIM,\n",
    "    ffn_proj_size=200,\n",
    "    use_bias_in_msr=False,\n",
    "    use_bias_in_mlp=True,\n",
    "    use_bias_in_msr_out=False,\n",
    "    use_default_gamma=True,\n",
    "    forward_impl='parallel'\n",
    ")\n",
    "timely_gpt_config.use_grad_ckp = False\n",
    "\n",
    "timely_gpt_model = TimelyGPT_CellLevel(\n",
    "    config=timely_gpt_config,\n",
    "    latent_dim=LATENT_DIM\n",
    ")\n",
    "\n",
    "# 3. Combined model\n",
    "model = VAETimelyGPT(vae, timely_gpt_model).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148eb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Phase 1: Fast Pre-training - Train only VAE Encoder and Decoder\n",
    "# ======================================================\n",
    "train_start_time = time.time()\n",
    "\n",
    "# Prepare time indices for training\n",
    "train_time_indices = torch.LongTensor(train_tps_idx).to(DEVICE)\n",
    "train_tps_tensor = torch.FloatTensor(train_tps_idx).to(DEVICE)\n",
    "\n",
    "print(\"\\n[Phase 1] Fast Pre-training: Training VAE Encoder and Decoder only...\")\n",
    "latent_encoder = model.vae.encoder\n",
    "obs_decoder = model.vae.decoder\n",
    "all_train_data = torch.cat(train_data, dim=0).to(DEVICE)\n",
    "\n",
    "if PRETRAIN_ITERS > 0:\n",
    "    # Only train encoder and decoder parameters\n",
    "    dim_reduction_params = itertools.chain(*[latent_encoder.parameters(), obs_decoder.parameters()])\n",
    "    dim_reduction_optimizer = torch.optim.Adam(params=dim_reduction_params, lr=PRETRAIN_LR, betas=(0.95, 0.99))\n",
    "    pretrain_scheduler = torch.optim.lr_scheduler.ExponentialLR(dim_reduction_optimizer, gamma=0.99)\n",
    "    latent_encoder.train()\n",
    "    obs_decoder.train()\n",
    "    \n",
    "    best_pretrain_loss = float('inf')\n",
    "    best_pretrain_state = None\n",
    "    \n",
    "    pbar = tqdm(range(PRETRAIN_ITERS), desc=\"Pre-training VAE\")\n",
    "    for i in pbar:\n",
    "        # Sample random batch from all training data\n",
    "        rand_idx = np.random.choice(all_train_data.shape[0], size=BATCH_SIZE, replace=False)\n",
    "        batch_data = all_train_data[rand_idx, :]\n",
    "        \n",
    "        dim_reduction_optimizer.zero_grad()\n",
    "        \n",
    "        # Encode -> sample -> decode (NO KL divergence term)\n",
    "        latent_mu, latent_log_var = latent_encoder(batch_data)\n",
    "        latent_std = torch.exp(0.5 * latent_log_var)\n",
    "        latent_sample = latent_mu + torch.randn_like(latent_std) * latent_std\n",
    "        recon_obs = obs_decoder(latent_sample)\n",
    "        \n",
    "        # Reconstruction MSE loss only (no KL divergence)\n",
    "        recon_loss = torch.mean((recon_obs - batch_data) ** 2)\n",
    "        recon_loss.backward()\n",
    "        dim_reduction_optimizer.step()\n",
    "        pretrain_scheduler.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\"Loss\": f\"{recon_loss.item():.6f}\"})\n",
    "        \n",
    "        # Save the best model\n",
    "        if recon_loss.item() < best_pretrain_loss:\n",
    "            best_pretrain_loss = recon_loss.item()\n",
    "            best_pretrain_state = {\n",
    "                'encoder': copy.deepcopy(latent_encoder.state_dict()),\n",
    "                'decoder': copy.deepcopy(obs_decoder.state_dict())\n",
    "            }\n",
    "\n",
    "    print(f\"Pre-training completed. Best loss: {best_pretrain_loss:.6f}\")\n",
    "    \n",
    "    # Load the best pre-trained model\n",
    "    if best_pretrain_state:\n",
    "        print(\"Loading best pre-trained model state...\")\n",
    "        latent_encoder.load_state_dict(best_pretrain_state['encoder'])\n",
    "        obs_decoder.load_state_dict(best_pretrain_state['decoder'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a92775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Phase 2: Dynamic Training - Train full model with Sinkhorn + Latent Smoothing\n",
    "# ======================================================\n",
    "print(\"\\n[Phase 2] Dynamic Training: Training full model (VAE + TimelyGPT)...\")\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR, betas=(0.95, 0.99))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "ot_solver = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05, scaling=0.5, debias=True, backend=\"tensorized\")\n",
    "loss_list = []\n",
    "iters_per_epoch = ITERS_PER_EPOCH\n",
    "\n",
    "epoch_pbar = tqdm(range(1, EPOCHS + 1), desc=\"Training Progress\")\n",
    "for epoch in epoch_pbar:\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # Inner loop for iterations within each epoch\n",
    "    for iter_idx in range(iters_per_epoch):\n",
    "        # Sample mini-batch from first timepoint\n",
    "        rand_idx = np.random.choice(train_data[0].shape[0], size=BATCH_SIZE, replace=False)\n",
    "        batch_data = train_data[0][rand_idx, :].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with data from first timepoint\n",
    "        recon_obs, first_latent_dist, first_tp_data, latent_seq = model(\n",
    "            batch_data, train_time_indices, forward_impl='parallel'\n",
    "        )\n",
    "        \n",
    "        # Compute loss: Sinkhorn OT + Latent Trajectory Smoothing\n",
    "        ot_loss = 0.0\n",
    "        for t_idx, t in enumerate(train_tps_idx):\n",
    "            pred_x = recon_obs[:, t_idx, :]  # [batch_size, n_genes]\n",
    "            true_x = train_data[t_idx].to(DEVICE)  # [n_cells_at_t, n_genes]\n",
    "            \n",
    "            # Subsample cells for efficient computation\n",
    "            subsample_size = min(200, true_x.shape[0])\n",
    "            subsample_idx = np.random.choice(true_x.shape[0], subsample_size, replace=False)\n",
    "            ot_loss += ot_solver(pred_x, true_x[subsample_idx])\n",
    "        \n",
    "        # Compute trajectory smoothness loss\n",
    "        latent_drift_loss = torch.mean((latent_seq[:, 1:, :] - latent_seq[:, :-1, :]) ** 2)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = ot_loss + LATENT_COEFF * latent_drift_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append((loss.item(), ot_loss.item(), latent_drift_loss.item()))\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Update epoch progress bar\n",
    "    avg_epoch_loss = np.mean(epoch_losses)\n",
    "    epoch_pbar.set_postfix({\n",
    "        \"Loss\": f\"{avg_epoch_loss:.4f}\",\n",
    "        \"LR\": f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
    "    })\n",
    "\n",
    "# Training summary\n",
    "train_duration = time.time() - train_start_time\n",
    "print(f\"\\nTraining completed! Total epochs: {EPOCHS}\")\n",
    "print(f\"Training time: {train_duration:.2f} seconds ({train_duration/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86547018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization - loss curve\n",
    "if len(loss_list) > 0:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot([each[0] for each in loss_list])\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title(\"OT Term\")\n",
    "    plt.plot([each[1] for each in loss_list])\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.title(\"Dynamic Reg\")\n",
    "    plt.plot([each[2] for each in loss_list])\n",
    "    plt.xlabel(\"Dynamic Learning Iter\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    loss_plot_path = \"figures/TimelyGPT_Loss.png\"\n",
    "    plt.savefig(loss_plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Loss plot saved to {loss_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions by sampling from t0 cell latent distribution\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 1. Encode all real t0 cells to get their latent distributions\n",
    "    t0_real_cells = traj_data[0].to(DEVICE)\n",
    "    mus, log_vars = model.vae.encoder(t0_real_cells)\n",
    "    stds = torch.exp(0.5 * log_vars)\n",
    "    num_real_t0_cells = t0_real_cells.shape[0]\n",
    "\n",
    "    # 2. Sample N_PRED_CELLS latent variables from this GMM\n",
    "    component_indices = np.random.choice(num_real_t0_cells, size=N_PRED_CELLS, replace=True)\n",
    "    selected_mus = mus[component_indices]\n",
    "    selected_stds = stds[component_indices]\n",
    "    \n",
    "    # Sample using reparameterization trick\n",
    "    eps = torch.randn_like(selected_stds)\n",
    "    z_initial_sampled = selected_mus + eps * selected_stds  # Shape: [N_PRED_CELLS, LATENT_DIM]\n",
    "    print(f\"Sampled {N_PRED_CELLS} initial latent states.\")\n",
    "\n",
    "    # 3. Use sampled latent states as input to TimelyGPT\n",
    "    all_time_indices = torch.LongTensor(all_tps).to(DEVICE)\n",
    "    \n",
    "    # Generate trajectory using TimelyGPT and decoder\n",
    "    # predictions_latent: [N_PRED_CELLS, n_all_tps, latent_dim]\n",
    "    predictions_latent = model.timely_gpt(z_initial_sampled, all_time_indices, forward_impl='parallel')\n",
    "    \n",
    "    # 4. Decode predictions to gene expression space\n",
    "    # all_recon_obs_tensor: [N_PRED_CELLS, n_tps, n_genes]\n",
    "    all_recon_obs_tensor = model.vae.decoder(predictions_latent)\n",
    "    \n",
    "    # Reshape for evaluation: [n_tps, n_cells, n_genes]\n",
    "    all_recon_obs = all_recon_obs_tensor.permute(1, 0, 2).cpu().numpy()\n",
    "\n",
    "\n",
    "print(f\"Predicted data shape: {all_recon_obs.shape}\")\n",
    "print(f\"Predicted cells at {len(all_tps)} timepoints\")\n",
    "\n",
    "# Evaluate predictions on all timepoints\n",
    "print(\"\\n Evaluation metrics for ALL timepoints:\")\n",
    "print(f\"{'Time':<6} {'Type':<6} {'OT':<10} {'L2':<10} {'CorrDist':<10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for t_idx in all_tps:\n",
    "    true_data_t = traj_data[t_idx].numpy()\n",
    "    pred_data_t = all_recon_obs[t_idx]\n",
    "    \n",
    "    # Compute standard metrics\n",
    "    metrics = globalEvaluation(true_data_t, pred_data_t)\n",
    "    \n",
    "    # Determine timepoint type\n",
    "    tp_type = \"TRAIN\" if t_idx in train_tps_idx else \"TEST\"\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"t={t_idx:<4} {tp_type:<6} {metrics['ot']:<10.4f} {metrics['l2']:<10.4f} \"\n",
    "          f\"{metrics['corr']:<10.4f}\")\n",
    "\n",
    "print(\"\\n Summary for TEST timepoints only:\")\n",
    "test_metrics = {'ot': [], 'l2': [], 'corr': []}\n",
    "for t_idx in test_tps_idx:\n",
    "    true_data_t = traj_data[t_idx].numpy()\n",
    "    pred_data_t = all_recon_obs[t_idx]\n",
    "    metrics = globalEvaluation(true_data_t, pred_data_t)\n",
    "    test_metrics['ot'].append(metrics['ot'])\n",
    "    test_metrics['l2'].append(metrics['l2'])\n",
    "    test_metrics['corr'].append(metrics['corr'])\n",
    "\n",
    "print(f\"Average OT: {np.mean(test_metrics['ot']):.4f} ± {np.std(test_metrics['ot']):.4f}\")\n",
    "print(f\"Average L2: {np.mean(test_metrics['l2']):.4f} ± {np.std(test_metrics['l2']):.4f}\")\n",
    "print(f\"Average CorrDist: {np.mean(test_metrics['corr']):.4f} ± {np.std(test_metrics['corr']):.4f}\")\n",
    "\n",
    "# Generate UMAP visualization\n",
    "print(\"\\nGenerating UMAP visualization...\")\n",
    "\n",
    "# Prepare true data\n",
    "true_data_list = [each.detach().numpy() if isinstance(each, torch.Tensor) else each for each in traj_data]\n",
    "true_all = np.concatenate(true_data_list, axis=0)\n",
    "\n",
    "# Fit UMAP on real data only\n",
    "true_umap_traj, umap_model, pca_model = umapWithPCA(true_all, n_neighbors=50, min_dist=0.1, pca_pcs=50)\n",
    "\n",
    "# Transform predictions using fitted UMAP\n",
    "pred_data_list = [all_recon_obs[t_idx] for t_idx in all_tps]\n",
    "pred_all = np.concatenate(pred_data_list, axis=0)\n",
    "pred_umap_traj = umap_model.transform(pca_model.transform(pred_all))\n",
    "\n",
    "# Generate timepoint labels\n",
    "true_cell_tps = np.concatenate([np.repeat(t_idx, traj_data[t_idx].shape[0]) for t_idx in all_tps])\n",
    "pred_cell_tps = np.concatenate([np.repeat(t_idx, all_recon_obs[t_idx].shape[0]) for t_idx in all_tps])\n",
    "\n",
    "# Create visualization\n",
    "save_path = \"figures/TimelyGPT_Results.png\"\n",
    "plotPredTestTime(true_umap_traj, pred_umap_traj, true_cell_tps, pred_cell_tps, test_tps_idx, save_path=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
