{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08b6175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PHS0404/ziyangs/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import geomloss # 需要 pip install geomloss\n",
    "\n",
    "# ==========================================\n",
    "# 1. 引用 TimelyGPT 模块\n",
    "# ==========================================\n",
    "project_root = str(pathlib.Path.cwd().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "try:\n",
    "    from model.TimelyGPT_CTS.layers.configs import RetNetConfig\n",
    "    from model.TimelyGPT_CTS.layers.Retention_layers import RetNetBlock\n",
    "except ImportError:\n",
    "    # 兼容处理\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f82c20-75d4-4afd-86ce-a9cce33e6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  4 00:38:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                  Off |\n",
      "| N/A   28C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04319be0-ae07-40b6-9582-a2f25328d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.0+cu121\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4717315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. 模型组件 (保持不变)\n",
    "# ==========================================\n",
    "class SpatialEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=2, d_model=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, d_model)\n",
    "        )\n",
    "    def forward(self, coords):\n",
    "        return self.net(coords)\n",
    "\n",
    "class GeneVAEEncoder(nn.Module):\n",
    "    def __init__(self, n_genes, latent_dim, hidden_dims=[512, 256]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = n_genes\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = h_dim\n",
    "        self.encoder_net = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_log_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "    def forward(self, x):\n",
    "        h = self.encoder_net(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_log_var(h)\n",
    "        return mu, log_var\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "class GeneDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, n_genes, hidden_dims=[256, 512]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = h_dim\n",
    "        layers.append(nn.Linear(hidden_dims[-1], n_genes))\n",
    "        self.decoder_net = nn.Sequential(*layers)\n",
    "    def forward(self, z):\n",
    "        return self.decoder_net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbcae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. 核心模型：Spatiotemporal GPT (自回归)\n",
    "# ==========================================\n",
    "class SpatiotemporalTimelyGPT(nn.Module):\n",
    "    def __init__(self, config, n_genes, n_timepoints):\n",
    "        super().__init__()\n",
    "        self.latent_dim = config.d_model\n",
    "        self.n_timepoints = n_timepoints\n",
    "        \n",
    "        self.gene_encoder = GeneVAEEncoder(n_genes, self.latent_dim)\n",
    "        self.spatial_encoder = SpatialEncoder(input_dim=2, d_model=self.latent_dim)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([RetNetBlock(config) for _ in range(config.num_layers)])\n",
    "        self.ln_f = nn.LayerNorm(config.d_model)\n",
    "        \n",
    "        self.gene_decoder = GeneDecoder(self.latent_dim, n_genes)\n",
    "\n",
    "    def forward(self, x_genes, x_coords):\n",
    "        # 1. 初始 Embedding (t=0 的状态估计)\n",
    "        mu, log_var = self.gene_encoder(x_genes)\n",
    "        z_gene = self.gene_encoder.reparameterize(mu, log_var)\n",
    "        z_space = self.spatial_encoder(x_coords)\n",
    "        z_combined = z_gene + z_space \n",
    "        \n",
    "        # 2. 自回归序列构造 (Left foot right foot)\n",
    "        # 输入：[State_0, State_0, ..., State_0] (复制T份)\n",
    "        # 机制：RetNet 是 Causal 的。\n",
    "        #   - 输出的第 0 步：只看第 0 个输入 (加 RoPE t=0)\n",
    "        #   - 输出的第 1 步：看第 0, 1 个输入 (加 RoPE t=0,1) -> 预测 t=1\n",
    "        # 这就像 GPT 输入 Prompt 生成后续一样\n",
    "        hidden_states = z_combined.unsqueeze(1).expand(-1, self.n_timepoints, -1)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            # RetNet 内部有 Causal Mask，保证只能看过去\n",
    "            block_out = block(hidden_states, sequence_offset=0, forward_impl='parallel')\n",
    "            hidden_states = block_out[0]\n",
    "            \n",
    "        hidden_states = self.ln_f(hidden_states)\n",
    "        \n",
    "        # 3. 解码整条轨迹\n",
    "        recon_seq = self.gene_decoder(hidden_states)\n",
    "        \n",
    "        return recon_seq, mu, log_var, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25772b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. 数据加载与挖空策略\n",
    "# ==========================================\n",
    "def load_and_split_data(path, hold_out_indices=[3, 6], n_top_genes=2000):\n",
    "    \"\"\"\n",
    "    hold_out_indices: 需要挖掉的时间点索引 (用于验证插值能力)\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {path}...\")\n",
    "    adata = sc.read_h5ad(path)\n",
    "    \n",
    "    print(\"Preprocessing...\")\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, subset=True)\n",
    "    \n",
    "    genes = adata.X\n",
    "    if hasattr(genes, \"toarray\"): genes = genes.toarray()\n",
    "    coords = adata.obsm['spatial']\n",
    "    \n",
    "    # 映射时间点\n",
    "    time_labels = sorted(adata.obs['timepoint'].unique())\n",
    "    time_map = {t: i for i, t in enumerate(time_labels)}\n",
    "    times = adata.obs['timepoint'].map(time_map).values.astype(int)\n",
    "    \n",
    "    print(f\"Total Timepoints: {len(time_labels)}\")\n",
    "    print(f\"Time Labels: {time_labels}\")\n",
    "    print(f\"Hold-out (Validation) Indices: {hold_out_indices} -> {[time_labels[i] for i in hold_out_indices]}\")\n",
    "    \n",
    "    # --- 关键：划分训练集和验证集 ---\n",
    "    # 训练集：不包含 hold_out_indices 时间点的细胞\n",
    "    train_mask = ~np.isin(times, hold_out_indices)\n",
    "    \n",
    "    train_data = {\n",
    "        'genes': genes[train_mask],\n",
    "        'coords': coords[train_mask],\n",
    "        'times': times[train_mask]\n",
    "    }\n",
    "    \n",
    "    # 验证集：只包含 hold_out_indices 时间点的细胞 (Ground Truth)\n",
    "    # 我们还需要 t=0 的细胞作为推断的起点(Source)，但评估只在 hold_out 点做\n",
    "    val_data = {}\n",
    "    for t_idx in hold_out_indices:\n",
    "        mask = times == t_idx\n",
    "        val_data[t_idx] = {\n",
    "            'genes': genes[mask],\n",
    "            'coords': coords[mask]\n",
    "        }\n",
    "        \n",
    "    # 获取 t=0 的数据用于验证时的输入 (Seed)\n",
    "    seed_mask = times == 0\n",
    "    seed_data = {\n",
    "        'genes': genes[seed_mask],\n",
    "        'coords': coords[seed_mask]\n",
    "    }\n",
    "        \n",
    "    return train_data, val_data, seed_data, genes.shape[1], len(time_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09638069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs available: 1\n",
      "  GPU 0: Tesla V100-PCIE-16GB\n",
      "Loading data from ../data/mouse.h5ad...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. 训练与验证逻辑\n",
    "# ==========================================\n",
    "def train_and_validate():\n",
    "    # 配置\n",
    "    DATA_PATH = '../data/mouse.h5ad'\n",
    "    LATENT_DIM = 64\n",
    "    BATCH_SIZE = 512\n",
    "    EPOCHS = 2  # 先训练2轮快速查看初步结果\n",
    "    # 假设有 10 个时间点 (0-9)，我们挖掉 3 和 6 做插值验证\n",
    "    HOLD_OUT = [3, 6] \n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs available: {num_gpus}\")\n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            print(f\"  GPU {i}: {gpu_name}\")\n",
    "    else:\n",
    "        print(\"No GPU available, using CPU\")\n",
    "    \n",
    "    # 1. 准备数据\n",
    "    train_data, val_data_dict, seed_data, n_genes, n_timepoints = \\\n",
    "        load_and_split_data(DATA_PATH, hold_out_indices=HOLD_OUT)\n",
    "    \n",
    "    # 训练集 Loader\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.FloatTensor(train_data['genes']),\n",
    "        torch.FloatTensor(train_data['coords']),\n",
    "        torch.LongTensor(train_data['times'])\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # 2. 模型\n",
    "    # 必须用真实的 Config\n",
    "    from model.TimelyGPT_CTS.layers.configs import RetNetConfig\n",
    "    config = RetNetConfig(d_model=LATENT_DIM, num_layers=3, num_heads=8, \n",
    "                          forward_impl='parallel', use_bias_in_msr_out=False)\n",
    "    \n",
    "    model = SpatiotemporalTimelyGPT(config, n_genes, n_timepoints).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # OT Loss Solver (用于验证集评估分布差异)\n",
    "    # Sinkhorn 损失能衡量两个点云(Point Cloud)之间的距离，不要求点对点对应\n",
    "    ot_solver = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05)\n",
    "\n",
    "    print(\"\\n=== 开始自回归训练 (带插值验证) ===\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        total_mse = 0\n",
    "        total_smooth = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Train Ep {epoch+1}\")\n",
    "        for batch_g, batch_c, batch_t in pbar:\n",
    "            batch_g, batch_c, batch_t = batch_g.to(DEVICE), batch_c.to(DEVICE), batch_t.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward: 预测所有时间点的轨迹 [B, T, Genes]\n",
    "            recon_seq, mu, log_var, z_seq = model(batch_g, batch_c)\n",
    "            \n",
    "            # Loss 1: 只在已知时间点计算 MSE\n",
    "            # (我们只知道当前细胞属于 batch_t，所以只监督 recon_seq[:, batch_t] 的输出)\n",
    "            # 使用 gather 提取对应时间点的预测\n",
    "            indices = batch_t.view(-1, 1, 1).expand(-1, 1, n_genes)\n",
    "            recon_at_t = torch.gather(recon_seq, 1, indices).squeeze(1)\n",
    "            \n",
    "            loss_mse = F.mse_loss(recon_at_t, batch_g)\n",
    "            \n",
    "            # Loss 2: 轨迹平滑 (这能帮助模型推断被挖掉的时间点)\n",
    "            # || z_{t+1} - z_t ||^2\n",
    "            loss_smooth = torch.mean((z_seq[:, 1:] - z_seq[:, :-1]) ** 2)\n",
    "            \n",
    "            loss = loss_mse + 0.0001 * (-0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())) + 1.0 * loss_smooth\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_mse += loss_mse.item()\n",
    "            total_smooth += loss_smooth.item()\n",
    "            \n",
    "            # Update progress bar with loss values\n",
    "            pbar.set_postfix({\n",
    "                \"Loss\": f\"{loss.item():.6f}\",\n",
    "                \"MSE\": f\"{loss_mse.item():.6f}\",\n",
    "                \"Smooth\": f\"{loss_smooth.item():.6f}\"\n",
    "            })\n",
    "            \n",
    "        # --- Validation Phase (Interpolation Check) ---\n",
    "        # 检查模型是否能“猜”出挖掉的时间点 (HOLE) 的数据分布\n",
    "        model.eval()\n",
    "        val_loss_dict = {}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 1. 拿一批 t=0 的细胞作为种子，生成整条轨迹\n",
    "            # 为了效率，随机采样 1000 个 t=0 细胞\n",
    "            idx = np.random.choice(len(seed_data['genes']), 1000, replace=True)\n",
    "            seed_g = torch.FloatTensor(seed_data['genes'][idx]).to(DEVICE)\n",
    "            seed_c = torch.FloatTensor(seed_data['coords'][idx]).to(DEVICE)\n",
    "            \n",
    "            # 预测所有时间点\n",
    "            pred_seq, _, _, _ = model(seed_g, seed_c) # [1000, T, Genes]\n",
    "            \n",
    "            # 2. 在挖掉的时间点 (Hold-out) 比较分布\n",
    "            for t_hole in HOLD_OUT:\n",
    "                # 预测的 t_hole 时刻的细胞群体\n",
    "                pred_pop = pred_seq[:, t_hole, :] # [1000, Genes]\n",
    "                \n",
    "                # 真实的 t_hole 时刻的细胞群体 (Ground Truth)\n",
    "                # 同样随机采样 1000 个\n",
    "                gt_idx = np.random.choice(len(val_data_dict[t_hole]['genes']), 1000, replace=True)\n",
    "                gt_pop = torch.FloatTensor(val_data_dict[t_hole]['genes'][gt_idx]).to(DEVICE)\n",
    "                \n",
    "                # 计算 OT Loss (分布距离)\n",
    "                # 这里的 Loss 越小，说明模型“插值”插得越准\n",
    "                ot_dist = ot_solver(pred_pop, gt_pop).item()\n",
    "                val_loss_dict[f'OT_t{t_hole}'] = ot_dist\n",
    "                \n",
    "        print(f\"Ep {epoch+1} | Train MSE: {total_mse/len(train_loader):.4f} | Smooth: {total_smooth/len(train_loader):.4f}\")\n",
    "        print(f\"       | Validation (Interpolation): {val_loss_dict}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists('../data/mouse.h5ad'):\n",
    "        train_and_validate()\n",
    "    else:\n",
    "        print(\"Dataset missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ec418c-316b-4559-a70e-771f84ac3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 3\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m12000\u001b[39m, \u001b[38;5;241m12000\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    a = torch.randn((12000, 12000), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df631e-164b-40d6-ac99-f0890110f84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
